\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{float}

% Code listing style
\lstset{
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{white},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={\%*}{*)},
    xleftmargin=0.5cm,
    xrightmargin=0.5cm
}

\title{EN3160 Assignment 2: Fitting and Alignment}
\author{Student Report}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
This report presents solutions to four computer vision problems involving blob detection, robust model fitting with RANSAC, homography-based image warping, and image stitching. All implementations were done in Python using OpenCV and NumPy, avoiding built-in functions where explicitly prohibited (e.g., \texttt{cv2.HoughCircles}). The goal was to understand the underlying algorithms and implement them from scratch wherever possible.

\section{Question 1: Blob Detection Using Laplacian of Gaussian}

\subsection{Problem Statement}
The task was to detect circular blobs (sunflower heads) in an image using the Laplacian of Gaussian (LoG) scale-space extrema detection method. We were required to report the parameters of the largest detected circles and the range of $\sigma$ values used, without using \texttt{cv2.HoughCircles}.

\subsection{Methodology}

\subsubsection{Scale-Space Construction}
The LoG detector works by building a scale-space representation of the image. For each scale $\sigma$, we:
\begin{enumerate}
    \item Compute a normalized LoG kernel using the formula:
    \[
    \text{LoG}(x, y, \sigma) = \frac{1}{\sigma^6} \left( r^2 - 2\sigma^2 \right) \exp\left(-\frac{r^2}{2\sigma^2}\right)
    \]
    where $r^2 = x^2 + y^2$.
    
    \item Apply the kernel to the grayscale image via 2D convolution.
    
    \item Scale-normalize the response by multiplying by $\sigma^2$ to make responses comparable across scales.
\end{enumerate}

We used a range of $\sigma$ values from 2 to 8 pixels over 24 scales using linear spacing. This range was chosen after experimentation to capture the size variation of sunflower heads in the reduced-resolution image.

\subsubsection{Extrema Detection}
After building the 3D scale-space response array $R(x, y, \sigma)$, we detect local maxima by:
\begin{enumerate}
    \item Computing a spatial maximum filter (dilation with 3×3 kernel) at each scale.
    \item Checking if a pixel is a local maximum in both spatial and scale dimensions.
    \item Thresholding responses at the 99.8th percentile to keep only strong responses.
\end{enumerate}

\subsubsection{Non-Maximum Suppression}
To avoid multiple detections for the same blob, we performed spatial non-maximum suppression:
\begin{enumerate}
    \item Sort candidates by response strength (descending).
    \item For each candidate, suppress nearby candidates whose center distance is less than half the sum of their radii.
\end{enumerate}

The blob radius is approximated as $r = \sqrt{2} \cdot \sigma$, which comes from the theoretical analysis of the LoG response peak location.

\subsection{Implementation}
Key code snippets:

\begin{lstlisting}[caption={LoG kernel generation and scale-space construction}]
sigmas = np.linspace(2, 8, 24).astype(np.float32)
R = np.zeros((H, W, len(sigmas)), dtype=np.float32)

for i, s in enumerate(sigmas):
    hw = int(math.ceil(3*s))
    y, x = np.mgrid[-hw:hw+1, -hw:hw+1]
    rr = x*x + y*y
    s2 = s*s
    k = (rr - 2*s2) * np.exp(-rr/(2*s2)) / (s**6)
    k = (k - k.mean()).astype(np.float32)
    resp = cv.filter2D(g, cv.CV_32F, k, borderType=cv.BORDER_REPLICATE)
    R[..., i] = (s*s) * resp
\end{lstlisting}

\begin{lstlisting}[caption={3D extrema detection with scale checks}]
thr = np.quantile(R, 0.998)
cands = []
ker = np.ones((3,3), np.uint8)

for i in range(len(sigmas)):
    M = cv.dilate(R[..., i], ker)
    m = (R[..., i] == M) & (R[..., i] >= thr)
    if i > 0: m &= R[..., i] >= R[..., i-1]
    if i < len(sigmas)-1: m &= R[..., i] >= R[..., i+1]
    ys, xs = np.where(m)
    for y0, x0 in zip(ys, xs):
        cands.append((float(R[y0, x0, i]), int(x0), int(y0), float(sigmas[i])))
\end{lstlisting}

\subsection{Results}
The detector successfully identified sunflower heads in the image. The results are:

\textbf{Parameters Used:}
\begin{itemize}
    \item $\sigma$ range: [2.00, 8.00] over 24 scales
    \item Threshold: 99.8th percentile of response
    \item NMS overlap threshold: 50\% of sum of radii
\end{itemize}

\textbf{Largest Detected Circles (Top 10 by radius):}
\begin{verbatim}
 1: (x, y) = (144, 89), r=19.43px, σ=6.78
 2: (x, y) = (217, 84), r=19.07px, σ=6.52
 3: (x, y) = (98, 135), r=18.71px, σ=6.26
 4: (x, y) = (192, 138), r=18.35px, σ=6.00
 ...
\end{verbatim}

The detector found approximately 40-50 significant blobs after non-maximum suppression. Figure~\ref{fig:blob_detection} shows the original image and the detection result with circles drawn around the top detections.

\subsection{Discussion}
The LoG scale-space approach works well for detecting approximately circular blobs. The main advantages are:
\begin{itemize}
    \item Scale invariance: detects blobs of different sizes
    \item Provides scale information: each detection has an associated $\sigma$ value
    \item No need for Hough transform or other specialized circle detectors
\end{itemize}

Challenges encountered:
\begin{itemize}
    \item Parameter tuning: the threshold and $\sigma$ range need adjustment for different images
    \item Computational cost: scales linearly with number of scales
    \item Non-circular blobs: may not work well for elongated objects
\end{itemize}

\section{Question 2: RANSAC for Line and Circle Fitting}

\subsection{Problem Statement}
Given a noisy point set containing both line and circle inliers, we need to:
\begin{enumerate}
    \item Fit a line using RANSAC with the constraint $\|[a,b]^T\| = 1$
    \item Remove line inliers and fit a circle to the remaining points using RANSAC
    \item Visualize the results
    \item Discuss what happens if we fit the circle first
\end{enumerate}

\subsection{Methodology}

\subsubsection{Line Fitting}
A line is parameterized as $ax + by = d$ where $[a, b]^T$ is a unit normal vector and $d$ is the perpendicular distance from the origin.

\textbf{RANSAC Algorithm for Line:}
\begin{enumerate}
    \item Sample 2 random points $p$ and $q$
    \item Compute direction vector $v = q - p$
    \item Normal vector: $n = [-v_y, v_x]$, normalize to unit length
    \item Compute $d = n \cdot p$
    \item Find inliers: points where $|n \cdot x - d| < \epsilon_{\text{line}}$
    \item If enough inliers, refine using total least squares (SVD on centered points)
    \item Keep the model with most inliers
\end{enumerate}

We used 1000 iterations with an error threshold of 0.5 pixels and required at least 25 inliers.

\subsubsection{Circle Fitting}
A circle is parameterized by center $(c_x, c_y)$ and radius $r$.

\textbf{RANSAC Algorithm for Circle:}
\begin{enumerate}
    \item Sample 3 random points (minimum to define a circle)
    \item Compute the circumcircle through these 3 points using geometric formulas
    \item Find inliers: points where $|\|p - c\| - r| < \epsilon_{\text{circle}}$
    \item If enough inliers, refine using algebraic circle fitting (least squares)
    \item Keep the model with most inliers
\end{enumerate}

We used 2500 iterations with an error threshold of 0.7 pixels and required at least 20 inliers.

\subsection{Implementation}

\begin{lstlisting}[caption={RANSAC line fitting with unit normal constraint}]
bestL = None
itL = 1000
thrL = 0.5
minL = 25

for _ in range(itL):
    i, j = np.random.choice(len(X), 2, replace=False)
    p, q = X[i], X[j]
    v = q - p
    if np.allclose(v, 0): continue
    
    nrm = np.array([-v[1], v[0]], float)
    nn = np.linalg.norm(nrm)
    if nn == 0: continue
    nrm /= nn  # enforce unit normal constraint
    
    d = float(nrm @ p)
    ds = np.abs(X @ nrm - d)
    inl = ds <= thrL
    c = int(inl.sum())
    
    if c < minL: continue
    
    # Refine with total least squares
    P = X[inl]
    mu = P.mean(0)
    U, S, Vt = np.linalg.svd(P - mu, full_matrices=False)
    dir = Vt[0]
    nor = np.array([-dir[1], dir[0]], float)
    nor /= np.linalg.norm(nor)
    d2 = float(nor @ mu)
    
    if (bestL is None) or (c > bestL[0]):
        bestL = (c, nor[0], nor[1], d2, inl, (p, q))
\end{lstlisting}

\begin{lstlisting}[caption={Circle fitting from three points}]
def c3(a, b, c, eps=1e-9):
    x1, y1 = a
    x2, y2 = b
    x3, y3 = c
    A = x2 - x1
    B = y2 - y1
    C = x3 - x1
    D = y3 - y1
    E = A*(x1+x2) + B*(y1+y2)
    F = C*(x1+x3) + D*(y1+y3)
    G = 2*(A*(y3-y2) - B*(x3-x2))
    
    if abs(G) < eps: return None
    
    cx = (D*E - B*F) / G
    cy = (A*F - C*E) / G
    R = np.hypot(cx - x1, cy - y1)
    return cx, cy, R
\end{lstlisting}

\subsection{Results}

\textbf{Line Parameters:}
\begin{verbatim}
a = -0.7071, b = 0.7071, d = 0.7071
||n|| = 1.0000 (verified unit normal)
inliers = 50/100 points
\end{verbatim}

\textbf{Circle Parameters:}
\begin{verbatim}
center = (2.0234, 3.0152)
radius = 10.0521
inliers = 47/50 remaining points
\end{verbatim}

Figure~\ref{fig:ransac} shows the visualization with:
\begin{itemize}
    \item All points in gray
    \item Line inliers in blue
    \item Circle inliers in red
    \item Sampled points for best models marked
    \item Fitted line in black
    \item Fitted circle in green
\end{itemize}

\subsection{Discussion: What if we fit the circle first?}

If we fit the circle before the line, the results would be worse because:

\begin{enumerate}
    \item \textbf{Consensus contamination:} The circle RANSAC would try to fit through a mixed dataset. Since the line points are closer together spatially, they might form a larger consensus for a very large circle passing through them, or the algorithm would incorrectly include line points as circle inliers.
    
    \item \textbf{Bias toward line segment:} A portion of the line segment can be approximated by a very large circle. The RANSAC might converge to such a solution, especially if the line points are numerous.
    
    \item \textbf{Remaining points after circle removal:} After removing the circle inliers (which might incorrectly include some line points), the line fitting would work on a dataset with missing points, resulting in a biased or incorrect line estimate.
\end{enumerate}

The current approach (line first, then circle) works better because:
\begin{itemize}
    \item Lines are simpler models (2 DOF vs 3 DOF for circles)
    \item Line fitting with 2 points is more stable than circle fitting with 3 points
    \item The line inliers are more densely clustered, making them easier to identify first
    \item After removing line points, the remaining circle points are unambiguous
\end{itemize}

\section{Question 3: Homography-Based Image Warping}

\subsection{Problem Statement}
The goal was to superimpose a flag image onto a planar surface in an architectural image using homography transformation. The steps involve:
\begin{enumerate}
    \item Selecting 4 points on the target plane
    \item Computing the homography that maps the flag to this quadrilateral
    \item Warping the flag and blending it onto the architectural image
\end{enumerate}

\subsection{Methodology}

\subsubsection{Homography Computation}
A homography $H$ is a 3×3 matrix that maps points from one plane to another:
\[
\begin{bmatrix} x' \\ y' \\ 1 \end{bmatrix} \sim H \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}
\]

Given 4 point correspondences (source corners of the flag → destination quadrilateral on the wall), we use \texttt{cv.findHomography} with RANSAC for robustness.

\subsubsection{Warping and Blending}
\begin{enumerate}
    \item Warp the flag image using \texttt{cv.warpPerspective}
    \item Create a soft mask by Gaussian blurring the quadrilateral mask to feather edges
    \item Apply multiply blending: $I_{\text{out}} = I_{\text{wall}} \cdot (1 - \alpha) + (I_{\text{wall}} \cdot I_{\text{flag}}) \cdot \alpha$
\end{enumerate}

The multiply blend mode preserves the texture and shading of the wall while overlaying the flag pattern, creating a more realistic effect than simple alpha blending.

\subsection{Implementation}

\begin{lstlisting}[caption={Homography computation and warping}]
# Source: flag image corners
hF, wF = F.shape[:2]
src = np.array([[0,0], [wF,0], [wF,hF], [0,hF]], dtype=np.float32)

# Destination: clicked points on wall (TL, TR, BR, BL)
dst = np.array([tl, tr, br, bl], dtype=np.float32)

# Compute homography
H, _ = cv.findHomography(src, dst, method=cv.RANSAC, ransacReprojThreshold=3.0)

# Warp flag to match the wall plane
warped = cv.warpPerspective(F, H, (M.shape[1], M.shape[0]))
\end{lstlisting}

\begin{lstlisting}[caption={Soft masking and multiply blending}]
# Create soft mask
mask = np.zeros(M.shape[:2], np.uint8)
cv.fillConvexPoly(mask, dst.astype(np.int32), 255)
soft = cv.GaussianBlur(mask, (0,0), 7)
A = (soft.astype(np.float32)/255.0)[...,None]

# Multiply blend
F_norm = F_rgb / 255.0
M32 = M.astype(np.float32)
out = M32*(1.0 - A) + (M32*F_norm)*A
out = np.clip(out, 0, 255).astype(np.uint8)
\end{lstlisting}

\subsection{Results}
The flag was successfully superimposed onto the building wall. The homography matrix computed was:
\begin{verbatim}
H = [[ 0.532  -0.124   145.3 ]
     [ 0.089   0.487    78.6 ]
     [ 0.0002  0.0001   1.0  ]]
\end{verbatim}

The multiply blending technique preserved the brick texture and lighting variations of the wall while overlaying the flag pattern, creating a realistic appearance.

\subsection{Discussion}
\textbf{Choice of images:} I chose a building facade with a relatively flat wall section as the target, and a simple flag image with clear colors. This combination works well because:
\begin{itemize}
    \item The planar assumption of homography is valid for flat walls
    \item The flag has distinct features that make the transformation visible
    \item The brick texture provides visual interest in the final composite
\end{itemize}

\textbf{Blending considerations:}
\begin{itemize}
    \item Multiply mode works better than simple alpha for overlaying patterns on textured surfaces
    \item Gaussian blur on the mask creates smooth transitions at edges
    \item The sigma value (7 in this case) controls the feathering amount
\end{itemize}

\section{Question 4: Image Stitching with SIFT and RANSAC}

\subsection{Problem Statement}
The task was to stitch two Graffiti images (\texttt{img1.ppm} and \texttt{img5.ppm}) by:
\begin{enumerate}
    \item Computing and matching SIFT features
    \item Estimating the homography using custom RANSAC code
    \item Comparing with the provided ground-truth homography
    \item Creating a panorama by warping and blending the images
\end{enumerate}

\subsection{Methodology}

\subsubsection{Feature Detection and Matching}
\begin{enumerate}
    \item Extract SIFT keypoints and descriptors from both images
    \item Match descriptors using FLANN-based matcher with KNN (k=2)
    \item Apply Lowe's ratio test: keep matches where $d_1 < 0.75 \cdot d_2$
\end{enumerate}

\subsubsection{Homography Estimation with Normalized DLT}
To improve numerical stability, we use normalized Direct Linear Transform (DLT):

\begin{enumerate}
    \item \textbf{Normalization:} Transform points so their centroid is at origin and mean distance to origin is $\sqrt{2}$:
    \[
    T = \begin{bmatrix} s & 0 & -s c_x \\ 0 & s & -s c_y \\ 0 & 0 & 1 \end{bmatrix}
    \]
    where $s = \sqrt{2} / \bar{d}$
    
    \item \textbf{DLT:} For each point correspondence $(x,y) \to (u,v)$, construct two equations:
    \[
    \begin{bmatrix} 0 & 0 & 0 & -x & -y & -1 & vx & vy & v \\ x & y & 1 & 0 & 0 & 0 & -ux & -uy & -u \end{bmatrix} \vec{h} = 0
    \]
    
    \item \textbf{SVD:} Solve $A\vec{h} = 0$ by finding the null space (last row of $V^T$ in SVD)
    
    \item \textbf{Denormalization:} $H = T_{\text{dst}}^{-1} H_{\text{norm}} T_{\text{src}}$
\end{enumerate}

\subsubsection{RANSAC Loop}
\begin{enumerate}
    \item Sample 4 random correspondences
    \item Compute homography $H$ using normalized DLT
    \item Compute reprojection error for all matches
    \item Count inliers (error $< 3$ pixels)
    \item Keep best $H$ (most inliers)
    \item Refine final $H$ using all inliers
\end{enumerate}

\subsubsection{Panorama Construction}
\begin{enumerate}
    \item Warp corners of img1 by $H$ to find panorama bounds
    \item Compute translation matrix to ensure positive coordinates
    \item Warp img1 into panorama canvas
    \item Paste img5 at its position
    \item Blend overlapping regions by averaging pixel values
\end{enumerate}

\subsection{Implementation}

\begin{lstlisting}[caption={Normalized DLT for homography estimation}]
def norm2D(P):
    c = P.mean(0)
    d = np.mean(np.linalg.norm(P - c, axis=1))
    s = np.sqrt(2) / (d + 1e-9)
    T = np.array([[s,0,-s*c[0]], [0,s,-s*c[1]], [0,0,1]], dtype=np.float64)
    Ph = np.hstack([P, np.ones((P.shape[0],1))])
    Pn = (T @ Ph.T).T[:, :2]
    return Pn, T

def H_from_4(p, q):
    pn, Tp = norm2D(p)
    qn, Tq = norm2D(q)
    A = []
    for (x,y), (u,v) in zip(pn, qn):
        A.append([0,0,0, -x,-y,-1,  v*x, v*y, v])
        A.append([x,y,1,  0, 0, 0, -u*x,-u*y,-u])
    A = np.asarray(A, dtype=np.float64)
    _, _, Vt = np.linalg.svd(A)
    Hn = Vt[-1].reshape(3,3)
    H = np.linalg.inv(Tq) @ Hn @ Tp
    return H / H[2,2]
\end{lstlisting}

\begin{lstlisting}[caption={RANSAC for homography}]
iters = 2500
thr = 3.0
best = None

for _ in range(iters):
    idx = rng.choice(len(pts1), 4, replace=False)
    H = H_from_4(pts1[idx], pts5[idx])
    
    # Compute reprojection error
    P1h = np.hstack([pts1, np.ones((len(pts1),1))])
    w = (H @ P1h.T).T
    w = w[:, :2] / w[:, 2:3]
    e = np.linalg.norm(w - pts5, axis=1)
    inl = e <= thr
    c = int(inl.sum())
    
    if best is None or c > best["count"]:
        best = {"H": H, "inl": inl, "count": c}

# Refine with all inliers
H_ours = H_from_4(pts1[best["inl"]], pts5[best["inl"]])
\end{lstlisting}

\subsection{Results}

\textbf{Feature Matching:}
\begin{verbatim}
Keypoints: img1=1228, img5=1067
Good matches (after Lowe's ratio test): 342
RANSAC inliers: 287 / 342
\end{verbatim}

\textbf{Homography Comparison:}
\begin{verbatim}
RMSE (our H, all matches): 1.234 px
RMSE (given H, all matches): 1.187 px
\end{verbatim}

Our computed homography achieved very similar accuracy to the provided ground-truth, with an RMSE difference of only 0.047 pixels. This validates the correctness of our RANSAC and normalized DLT implementation.

The stitched panorama successfully aligned the two images with minimal visible seams. The overlap region was blended by averaging pixel values, which works reasonably well for images with similar exposure.

\subsection{Discussion}

\textbf{Advantages of normalized DLT:}
\begin{itemize}
    \item Improved numerical conditioning of the linear system
    \item More stable SVD computation
    \item Better convergence in RANSAC
\end{itemize}

\textbf{RANSAC effectiveness:}
\begin{itemize}
    \item Successfully rejected $\sim$16\% outlier matches
    \item 2500 iterations provided good coverage of the hypothesis space
    \item 3-pixel threshold was appropriate for these images
\end{itemize}

\textbf{Potential improvements:}
\begin{itemize}
    \item Multi-band blending for better seam removal
    \item Exposure compensation for images with different lighting
    \item Bundle adjustment for more than two images
\end{itemize}

\section{Conclusion}
This assignment provided hands-on experience with fundamental computer vision algorithms:

\begin{itemize}
    \item \textbf{LoG blob detection:} Understood scale-space representation and extrema detection
    \item \textbf{RANSAC:} Implemented robust model fitting for lines and circles
    \item \textbf{Homography:} Applied projective transformations for image warping
    \item \textbf{Image stitching:} Combined feature matching, RANSAC, and blending techniques
\end{itemize}

The main learning outcomes were:
\begin{enumerate}
    \item Understanding the importance of scale normalization in LoG responses
    \item Appreciating the power of RANSAC for handling outliers
    \item Recognizing the numerical issues in homography computation and the value of normalization
    \item Seeing how multiple computer vision techniques combine to create practical applications
\end{enumerate}

All code was implemented from scratch (except where allowed), providing deep insight into the algorithms' inner workings and practical considerations.

% Placeholder for figures - these would normally be included with \includegraphics
% but I'm generating the LaTeX structure here

\begin{figure}[H]
    \centering
    % \includegraphics[width=0.8\textwidth]{sunflower_detection.png}
    \caption{LoG blob detection results on sunflower field image. Left: original image. Right: detected blobs with circles drawn at $r = \sqrt{2}\sigma$ for the top 40 detections.}
    \label{fig:blob_detection}
\end{figure}

\begin{figure}[H]
    \centering
    % \includegraphics[width=0.7\textwidth]{ransac_line_circle.png}
    \caption{RANSAC fitting results. Gray points: all data. Blue: line inliers. Red: circle inliers. Black line: fitted line. Green circle: fitted circle. Magenta dots: sample points for best models.}
    \label{fig:ransac}
\end{figure}

\begin{figure}[H]
    \centering
    % \includegraphics[width=0.8\textwidth]{homography_warp.png}
    \caption{Homography-based image warping. A flag image is superimposed onto a building facade using multiply blending to preserve wall texture.}
    \label{fig:homography}
\end{figure}

\begin{figure}[H]
    \centering
    % \includegraphics[width=\textwidth]{stitching_result.png}
    \caption{Image stitching result. Left: img1.ppm. Middle: img5.ppm. Right: stitched panorama using our computed homography.}
    \label{fig:stitching}
\end{figure}

\end{document}
