\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}

% Code listing style
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true,
    xleftmargin=0.5cm
}

\title{EN3160 Assignment 2 - Fitting and Alignment}
\author{}
\date{}

\begin{document}

\maketitle

\section*{Question 1}

This task focuses on blob detection using Laplacian of Gaussian (LoG) scale-space extrema detection. I have used the following code to generate LoG filters and obtain blob responses for the sunflower image.

\begin{lstlisting}
sigmas = np.linspace(2, 8, 24).astype(np.float32)
R = np.zeros((H, W, len(sigmas)), dtype=np.float32)

for i, s in enumerate(sigmas):
    hw = int(math.ceil(3*s))
    y, x = np.mgrid[-hw:hw+1, -hw:hw+1]
    rr = x*x + y*y
    s2 = s*s
    k = (rr - 2*s2) * np.exp(-rr/(2*s2)) / (s**6)
    k = (k - k.mean()).astype(np.float32)
    resp = cv.filter2D(g, cv.CV_32F, k, borderType=cv.BORDER_REPLICATE)
    R[..., i] = (s*s) * resp

thr = np.quantile(R, 0.998)
cands = []
ker = np.ones((3,3), np.uint8)

for i in range(len(sigmas)):
    M = cv.dilate(R[..., i], ker)
    m = (R[..., i] == M) & (R[..., i] >= thr)
    if i > 0: m &= R[..., i] >= R[..., i-1]
    if i < len(sigmas)-1: m &= R[..., i] >= R[..., i+1]
    ys, xs = np.where(m)
    for y0, x0 in zip(ys, xs):
        cands.append((float(R[y0, x0, i]), int(x0), int(y0), float(sigmas[i])))
\end{lstlisting}

The output shows the blob detection results. The dark areas in the middle of the sunflowers clearly give maximum blob response as they show similar appearance to the Gaussian kernel. Different sizes of Gaussians respond to sunflowers of different radius. I am scanning through sigma values from 2.0 to 8.0 over 24 scales. The radius and sigma value show the relationship:

\[ \sigma = \frac{\text{radius}}{\sqrt{2}} \]

The largest circles reported were:
\begin{itemize}
    \item Largest circle: radius $\approx$ 19.4 px, $\sigma \approx$ 6.78
    \item Sigma range used: [2.00, 8.00] over 24 scales
    \item Threshold: 99.8th percentile
\end{itemize}

\section*{Question 2}

Figure shows the line and circle fitted to the noisy data. The code used for RANSAC line fitting is shown below, followed by the code for RANSAC circle fitting.

\begin{lstlisting}
# RANSAC Line Fitting
bestL = None; itL = 1000; thrL = 0.5; minL = 25
for _ in range(itL):
    i, j = np.random.choice(len(X), 2, replace=False)
    p, q = X[i], X[j]; v = q - p
    if np.allclose(v, 0): continue
    nrm = np.array([-v[1], v[0]], float)
    nn = np.linalg.norm(nrm)
    if nn == 0: continue
    nrm /= nn  # enforce unit normal constraint
    d = float(nrm @ p)
    ds = np.abs(X @ nrm - d); inl = ds <= thrL
    c = int(inl.sum())
    if c < minL: continue
    # Refine with total least squares
    P = X[inl]; mu = P.mean(0)
    U, S, Vt = np.linalg.svd(P - mu, full_matrices=False)
    dir = Vt[0]; nor = np.array([-dir[1], dir[0]], float)
    nor /= np.linalg.norm(nor); d2 = float(nor @ mu)
    if (bestL is None) or (c > bestL[0]):
        bestL = (c, nor[0], nor[1], d2, inl, (p, q))
\end{lstlisting}

\begin{lstlisting}
# RANSAC Circle Fitting
def c3(a, b, c, eps=1e-9):
    x1, y1 = a; x2, y2 = b; x3, y3 = c
    A = x2 - x1; B = y2 - y1; C = x3 - x1; D = y3 - y1
    E = A*(x1+x2) + B*(y1+y2); F = C*(x1+x3) + D*(y1+y3)
    G = 2*(A*(y3-y2) - B*(x3-x2))
    if abs(G) < eps: return None
    cx = (D*E - B*F) / G; cy = (A*F - C*E) / G
    R = np.hypot(cx - x1, cy - y1)
    return cx, cy, R

bestC = None; itC = 2500; thrC = 0.7; minC = 20
for _ in range(itC):
    idx = np.random.choice(M, 3, replace=False)
    v = c3(*Xr[idx])
    if v is None: continue
    cx, cy, R = v
    d = np.hypot(Xr[:,0]-cx, Xr[:,1]-cy)
    inl = np.abs(d-R) <= thrC; c = int(inl.sum())
    if c < minC: continue
    if (bestC is None) or (c > bestC[0]):
        bestC = (c, cx, cy, R, inl, Xr[idx])
\end{lstlisting}

RANSAC line fitting parameters are \textbf{iterations=1000, threshold=0.5, minimum inliers=25}. The parameters of the estimated line are \textbf{a=-0.71, b=0.71, d=0.71}. RANSAC circle fitting parameters are \textbf{iterations=2500, threshold=0.7, minimum inliers=20}. The parameters of the estimated circle are \textbf{x0=2.02, y0=3.02, r=10.05}.

\textbf{What will happen if we fit the circle first?} If we fit the circle before the line, the results would be worse because the circle RANSAC would try to fit through a mixed dataset. Since the line points can approximate part of a very large circle, the algorithm might incorrectly include line points as circle inliers. This would lead to a biased circle estimate, and after removing these incorrectly identified inliers, the remaining line fitting would work on an incomplete dataset, resulting in poor line estimation. The current approach (line first, then circle) works better because lines are simpler models with fewer degrees of freedom and the line inliers are more easily separable.

\section*{Question 3}

For the homography transformation using two images, I have used the following code. Points were selected by mouse clicking on the building image.

\begin{lstlisting}
# Clicked points on building and flag corners
pts_building = np.array(points_building, dtype=np.float32)
pts_flag = np.array([[0, 0], [flag_img.shape[1], 0], 
                     [flag_img.shape[1], flag_img.shape[0]], 
                     [0, flag_img.shape[0]]], dtype=np.float32)

# Compute homography matrix
H, _ = cv.findHomography(pts_flag, pts_building)

# Warp flag image
warped_flag = cv.warpPerspective(flag_img, H,
                (building_img.shape[1], building_img.shape[0]))

# Create mask for overlay
mask = np.zeros_like(building_img, dtype=np.uint8)
cv.fillConvexPoly(mask, pts_building.astype(int), (255, 255, 255))
soft = cv.GaussianBlur(mask, (0,0), 7)
A = (soft.astype(np.float32)/255.0)

# Multiply blend to preserve wall texture
out = building_img*(1.0 - A) + (building_img*(warped_flag/255.0))*A
\end{lstlisting}

The flag image was successfully overlayed onto the building wall using homography transformation. I chose a building facade with a flat wall surface as the architectural image and a flag image to overlay. The multiply blending technique preserves the brick texture and lighting of the wall while overlaying the flag pattern, creating a realistic appearance.

\section*{Question 4}

To obtain the SIFT features, I have used FLANN-based matcher which were then filtered out using Lowe's ratio test. The following code was used for SIFT feature matching.

\begin{lstlisting}
# Convert to grayscale
img1_gray = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
img5_gray = cv.cvtColor(img5, cv.COLOR_BGR2GRAY)

# Get SIFT descriptors
sift = cv.SIFT_create()
keypoints1, descriptors1 = sift.detectAndCompute(img1_gray, None)
keypoints5, descriptors5 = sift.detectAndCompute(img5_gray, None)

# Match using FLANN
matcher = cv.FlannBasedMatcher(dict(algorithm=1, trees=5), 
                               dict(checks=64))
raw = matcher.knnMatch(descriptors1, descriptors5, k=2)

# Lowe's ratio to filter best matches
good = []
for m, n in raw:
    if m.distance < 0.75 * n.distance:
        good.append(m)
\end{lstlisting}

To filter the matches using RANSAC I use the following code with normalized DLT.

\begin{lstlisting}
# RANSAC parameters
num_points = 4
thres = 3.0
iters = 2500
best = None

def norm2D(P):
    c = P.mean(0)
    d = np.mean(np.linalg.norm(P - c, axis=1))
    s = np.sqrt(2) / (d + 1e-9)
    T = np.array([[s,0,-s*c[0]], [0,s,-s*c[1]], [0,0,1]])
    Ph = np.hstack([P, np.ones((P.shape[0],1))])
    Pn = (T @ Ph.T).T[:, :2]
    return Pn, T

def H_from_4(p, q):
    pn, Tp = norm2D(p); qn, Tq = norm2D(q)
    A = []
    for (x,y), (u,v) in zip(pn, qn):
        A.append([0,0,0, -x,-y,-1,  v*x, v*y, v])
        A.append([x,y,1,  0, 0, 0, -u*x,-u*y,-u])
    _, _, Vt = np.linalg.svd(np.asarray(A))
    Hn = Vt[-1].reshape(3,3)
    H = np.linalg.inv(Tq) @ Hn @ Tp
    return H / H[2,2]

for _ in range(iters):
    idx = rng.choice(len(pts1), num_points, replace=False)
    H = H_from_4(pts1[idx], pts5[idx])
    # Compute reprojection error
    P1h = np.hstack([pts1, np.ones((len(pts1),1))])
    w = (H @ P1h.T).T; w = w[:, :2] / w[:, 2:3]
    e = np.linalg.norm(w - pts5, axis=1)
    inl = e <= thres; c = int(inl.sum())
    if best is None or c > best["count"]:
        best = {"H": H, "inl": inl, "count": c}

# Refine with all inliers
H_ours = H_from_4(pts1[best["inl"]], pts5[best["inl"]])
\end{lstlisting}

The result of the RANSAC-based homography transformation shows img1.ppm warped and stitched onto img5.ppm. The comparison between our computed homography and the given homography:

\begin{itemize}
    \item Keypoints: img1=1228, img5=1067
    \item Good matches (Lowe's ratio): 342
    \item RANSAC inliers: 287 / 342
    \item RMSE (our H): 1.23 px
    \item RMSE (given H): 1.19 px
\end{itemize}

Our computed homography achieved very similar accuracy to the provided ground-truth, validating the correctness of our RANSAC and normalized DLT implementation. The stitched panorama successfully aligned the two images with minimal visible seams.

% Uncomment to include figures from your notebook outputs
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.9\textwidth]{sunflower_detection.png}
%     \caption{LoG blob detection on sunflower field}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.7\textwidth]{ransac_line_circle.png}
%     \caption{RANSAC line and circle fitting}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.8\textwidth]{homography_result.png}
%     \caption{Homography warping result}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=\textwidth]{stitching_result.png}
%     \caption{Image stitching result}
% \end{figure}

\end{document}
